{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884f43de",
   "metadata": {
    "papermill": {
     "duration": 0.025578,
     "end_time": "2023-05-23T08:57:17.009095",
     "exception": false,
     "start_time": "2023-05-23T08:57:16.983517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CAFA 5 Competition : Protein Function Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d46d64",
   "metadata": {
    "papermill": {
     "duration": 0.014142,
     "end_time": "2023-05-23T08:57:17.038058",
     "exception": false,
     "start_time": "2023-05-23T08:57:17.023916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Problem Framing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b6ed9",
   "metadata": {
    "papermill": {
     "duration": 0.014236,
     "end_time": "2023-05-23T08:57:17.066689",
     "exception": false,
     "start_time": "2023-05-23T08:57:17.052453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This Kaggle competition aims to predict the function of proteins using their amino-acid sequences and additional data. Understanding protein function is crucial for comprehending cellular processes and developing new treatments for diseases. With the abundance of genomic sequence data available, assigning accurate biological functions to proteins becomes challenging due to their multifunctionality and interactions with various partners. This competition, hosted by the Function Community of Special Interest (Function-COSI), brings together computational biologists, experimental biologists, and biocurators to improve protein function prediction through data science and machine learning approaches. The goal is to contribute to advancements in medicine, agriculture, and overall human and animal health."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8298351",
   "metadata": {
    "papermill": {
     "duration": 0.013909,
     "end_time": "2023-05-23T08:57:17.094761",
     "exception": false,
     "start_time": "2023-05-23T08:57:17.080852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![image-intro](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Computational_solvent_mapping_of_AMA1_using_FTMAP.TIF/lossy-page1-500px-Computational_solvent_mapping_of_AMA1_using_FTMAP.TIF.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d06bd",
   "metadata": {
    "papermill": {
     "duration": 0.014224,
     "end_time": "2023-05-23T08:57:17.123483",
     "exception": false,
     "start_time": "2023-05-23T08:57:17.109259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What to submit ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c4e1f2",
   "metadata": {
    "papermill": {
     "duration": 0.014004,
     "end_time": "2023-05-23T08:57:17.151827",
     "exception": false,
     "start_time": "2023-05-23T08:57:17.137823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This competition evaluates participants' predictions of Gene Ontology (GO) terms for protein sequences. The evaluation is performed on a test set of proteins that initially have no assigned functions but may accumulate experimental annotations after the submission deadline. The test set is divided into three subontologies: Molecular Function (MF), Biological Process (BP), and Cellular Component (CC). Participants are scored separately for each subontology. The final performance measure is the arithmetic mean of the maximum F-measures calculated on the three subontologies. Weighted precision and recall are used, taking into account the hierarchical structure of the GO. The evaluation code is publicly available. The leaderboard displays performance on a subset of proteins not included in the final test set, so generalization performance is crucial. Submission files should contain protein-target pairs with corresponding GO terms and estimated probabilities, within a specific score range. The predictions are propagated to parent terms if not explicitly listed. There is a limit on the number of terms associated with each protein. If a protein is not listed in the submission file, it is assumed that all predictions for that protein are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47cc5693",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:17.181960Z",
     "iopub.status.busy": "2023-05-23T08:57:17.181536Z",
     "iopub.status.idle": "2023-05-23T08:57:17.187170Z",
     "shell.execute_reply": "2023-05-23T08:57:17.186109Z"
    },
    "papermill": {
     "duration": 0.024591,
     "end_time": "2023-05-23T08:57:17.190594",
     "exception": false,
     "start_time": "2023-05-23T08:57:17.166003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# sub = pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/sample_submission.tsv\", sep= \"\\t\", header = None)\n",
    "# sub.columns = [\"The Protein ID\", \"The Gene Ontology term (GO) ID\", \"Predicted link probability that GO appear in Protein\"]\n",
    "# sub.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a8295d",
   "metadata": {
    "papermill": {
     "duration": 0.014475,
     "end_time": "2023-05-23T08:57:17.219367",
     "exception": false,
     "start_time": "2023-05-23T08:57:17.204892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The evaluation metric used in this competition is the weighted F-measure, which combines precision and recall, taking into account the hierarchical structure of the Gene Ontology (GO). The formula for calculating the weighted F-measure is as follows:\n",
    "\n",
    "$Weighted \\ F-measure = \\frac{(1 + β^2) * (weighted \\ precision * weighted recall)}{((β^2 * weighted \\ precision) + weighted \\ recall)}$\n",
    "\n",
    "where:\n",
    "- β is a parameter that controls the trade-off between precision and recall. In this competition, β is set to 1, resulting in an equal weighting of precision and recall.\n",
    "- Weighted precision is the precision score, considering the weights of the predicted terms. It is calculated as the sum of the products of the predicted term's weight and its true positive count, divided by the sum of the weights of all predicted terms.\n",
    "- Weighted recall is the recall score, considering the weights of the true positive terms. It is calculated as the sum of the products of the true positive term's weight and its count, divided by the sum of the weights of all true positive terms.\n",
    "\n",
    "Note: The specific formulas for weighted precision and weighted recall are provided in the competition materials and utilize additional information such as term weights and true positive counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413df2d4",
   "metadata": {
    "papermill": {
     "duration": 0.013938,
     "end_time": "2023-05-23T08:57:17.247395",
     "exception": false,
     "start_time": "2023-05-23T08:57:17.233457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# General Baseline in this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25966daf",
   "metadata": {
    "papermill": {
     "duration": 0.013979,
     "end_time": "2023-05-23T08:57:17.275451",
     "exception": false,
     "start_time": "2023-05-23T08:57:17.261472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- **1 - Collect Embedding vectors from pre-trained protein function prediction models (T5, ProtBERT or EMS2) :**\n",
    "\n",
    "Sources for embeddings vectors : \n",
    "- *T5* : https://www.kaggle.com/datasets/sergeifironov/t5embeds\n",
    "\n",
    "- *ProtBERT* : https://www.kaggle.com/datasets/henriupton/protbert-embeddings-for-cafa5\n",
    "\n",
    "- *EMS2* : https://www.kaggle.com/datasets/viktorfairuschin/cafa-5-ems-2-embeddings-numpy\n",
    "\n",
    "- **2 - Generate labels from train_terms file** : by considering the top K most common GO terms in all Proteins set, generate for each protein a sparse vector of length K to indicate the true probabilities that each of the K GO terms are in the Protein (0 or 1). Here we retain K = 600\n",
    "\n",
    "- **3 - Create Pytorch Dataset class that can handle Protein ID and embeddings**.\n",
    "\n",
    "- **4 - Create Pytorch Model class for prediction** : can be any architecture of Multilabel classification model that can turn embeddings of shape (E,) to probabilities of shape (K,). Here we explore **MultiLayerPerceptron** and **ConvNN1d** Networks.\n",
    "\n",
    "- **5 - Make Cross Validation w.r.t the F-1 measure and do Hyperparameter tuning thanks to Weights and Biases package (Wandb)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bee910",
   "metadata": {
    "papermill": {
     "duration": 0.013858,
     "end_time": "2023-05-23T08:57:17.303676",
     "exception": false,
     "start_time": "2023-05-23T08:57:17.289818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![baseline-image](https://www.researchgate.net/publication/334642149/figure/fig1/AS:783995214249986@1563930433525/Flow-chart-of-STRING2GO-based-protein-function-prediction-method.png)\n",
    "\n",
    "## **Flow-chart of STRING2GO-based protein function prediction method**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a46bb",
   "metadata": {
    "papermill": {
     "duration": 0.013886,
     "end_time": "2023-05-23T08:57:17.331659",
     "exception": false,
     "start_time": "2023-05-23T08:57:17.317773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# So now lets get started !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3519fb",
   "metadata": {
    "papermill": {
     "duration": 0.014155,
     "end_time": "2023-05-23T08:57:17.359953",
     "exception": false,
     "start_time": "2023-05-23T08:57:17.345798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Imports / Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "128d570e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:17.390203Z",
     "iopub.status.busy": "2023-05-23T08:57:17.389842Z",
     "iopub.status.idle": "2023-05-23T08:57:30.820843Z",
     "shell.execute_reply": "2023-05-23T08:57:30.819823Z"
    },
    "papermill": {
     "duration": 13.448624,
     "end_time": "2023-05-23T08:57:30.823036",
     "exception": false,
     "start_time": "2023-05-23T08:57:17.374412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cafa-5-protein-function-prediction/sample_submission.tsv\n",
      "/kaggle/input/cafa-5-protein-function-prediction/IA.txt\n",
      "/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta\n",
      "/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset-taxon-list.tsv\n",
      "/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv\n",
      "/kaggle/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta\n",
      "/kaggle/input/cafa-5-protein-function-prediction/Train/train_taxonomy.tsv\n",
      "/kaggle/input/cafa-5-protein-function-prediction/Train/go-basic.obo\n",
      "/kaggle/input/train-tragets-top-500/train_targets_BPO_top_500.pkl\n",
      "/kaggle/input/train-tragets-top-500/train_targets_MFO_top_500.pkl\n",
      "/kaggle/input/train-tragets-top-500/train_targets_CCO_top_500.pkl\n",
      "/kaggle/input/protbert-embeddings-for-cafa5/train_ids.npy\n",
      "/kaggle/input/protbert-embeddings-for-cafa5/train_embeddings.npy\n",
      "/kaggle/input/protbert-embeddings-for-cafa5/test_ids.npy\n",
      "/kaggle/input/protbert-embeddings-for-cafa5/test_embeddings.npy\n",
      "/kaggle/input/t5embeds/train_ids.npy\n",
      "/kaggle/input/t5embeds/test_embeds.npy\n",
      "/kaggle/input/t5embeds/train_embeds.npy\n",
      "/kaggle/input/t5embeds/test_ids.npy\n",
      "/kaggle/input/ensemble-embedding-for-cfa/train_ids.npy\n",
      "/kaggle/input/ensemble-embedding-for-cfa/train_embeddings.npy\n",
      "/kaggle/input/ensemble-embedding-for-cfa/test_ids.npy\n",
      "/kaggle/input/ensemble-embedding-for-cfa/test_embeddings.npy\n",
      "/kaggle/input/cfca-models/BPO_Ensemble2_500_linear_0.2250145967692545.pth\n",
      "/kaggle/input/cfca-models/CCO_Ensemble2_500_linear_0.14624455499730699.pth\n",
      "/kaggle/input/cfca-models/MFO_Ensemble2_500_linear_0.15245565555749402.pth\n",
      "/kaggle/input/cafa-5-ems-2-embeddings-numpy/train_ids.npy\n",
      "/kaggle/input/cafa-5-ems-2-embeddings-numpy/train_embeddings.npy\n",
      "/kaggle/input/cafa-5-ems-2-embeddings-numpy/test_ids.npy\n",
      "/kaggle/input/cafa-5-ems-2-embeddings-numpy/test_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "MAIN_DIR = \"/kaggle/input/cafa-5-protein-function-prediction\"\n",
    "\n",
    "# UTILITARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "# import tensorflow as tf\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# TORCH MODULES FOR METRICS COMPUTATION :\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "# WANDB FOR LIGHTNING :\n",
    "import wandb\n",
    "\n",
    "# FILES VISUALIZATION\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b16fb9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:30.854634Z",
     "iopub.status.busy": "2023-05-23T08:57:30.853210Z",
     "iopub.status.idle": "2023-05-23T08:57:30.867826Z",
     "shell.execute_reply": "2023-05-23T08:57:30.866987Z"
    },
    "papermill": {
     "duration": 0.032226,
     "end_time": "2023-05-23T08:57:30.869919",
     "exception": false,
     "start_time": "2023-05-23T08:57:30.837693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    train_sequences_path = MAIN_DIR  + \"/Train/train_sequences.fasta\"\n",
    "    train_labels_path = MAIN_DIR + \"/Train/train_terms.tsv\"\n",
    "    test_sequences_path = MAIN_DIR + \"/Test (Targets)/testsuperset.fasta\"\n",
    "    \n",
    "    num_labels = 500\n",
    "    n_epochs = 10\n",
    "    batch_size = 128\n",
    "    lr = 1e-3\n",
    "    early_stop = 7\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd378d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:30.900492Z",
     "iopub.status.busy": "2023-05-23T08:57:30.900188Z",
     "iopub.status.idle": "2023-05-23T08:57:30.905034Z",
     "shell.execute_reply": "2023-05-23T08:57:30.904091Z"
    },
    "papermill": {
     "duration": 0.022622,
     "end_time": "2023-05-23T08:57:30.907397",
     "exception": false,
     "start_time": "2023-05-23T08:57:30.884775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2456ef1c",
   "metadata": {
    "papermill": {
     "duration": 0.014493,
     "end_time": "2023-05-23T08:57:30.936518",
     "exception": false,
     "start_time": "2023-05-23T08:57:30.922025",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea5ae12",
   "metadata": {
    "papermill": {
     "duration": 0.014418,
     "end_time": "2023-05-23T08:57:30.965497",
     "exception": false,
     "start_time": "2023-05-23T08:57:30.951079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Use ProtBERT/T5 embedding vectors for each Sequence ID and its associated Protein Sequence. \n",
    "\n",
    "- Define a Pytorch Dataset to load all ids/sequences of the train+test sets and their respective ProtBert embeddings\n",
    "\n",
    "- Define Pytorch Model architecture in order to use these embeddings to proceed classification task : to each ID we associate a probability to be associated to each GO term **For this part, just consider the top_n most common GO terms as labels**\n",
    "\n",
    "- Return desired probabilities for test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb3dab4",
   "metadata": {
    "papermill": {
     "duration": 0.014513,
     "end_time": "2023-05-23T08:57:30.994433",
     "exception": false,
     "start_time": "2023-05-23T08:57:30.979920",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Collect ProtBERT Embedding Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3231f",
   "metadata": {
    "papermill": {
     "duration": 0.014307,
     "end_time": "2023-05-23T08:57:31.023216",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.008909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Here is a Dataset Card I have created if you want to understand better what are pre-trained model embedding vectors, and if you want to download it directly from it : https://www.kaggle.com/datasets/henriupton/protbert-embeddings-for-cafa5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d5e023",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T08:54:24.396067Z",
     "iopub.status.busy": "2023-05-05T08:54:24.395576Z",
     "iopub.status.idle": "2023-05-05T08:54:35.014197Z",
     "shell.execute_reply": "2023-05-05T08:54:35.012847Z",
     "shell.execute_reply.started": "2023-05-05T08:54:24.396028Z"
    },
    "papermill": {
     "duration": 0.014379,
     "end_time": "2023-05-23T08:57:31.052022",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.037643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### SCRIPT FOR VECTOR EMBEDDINGS COLLECTING #####\n",
    "#### RUN THIS ONLY ONE TIME AND SAVE IT IN LOCAL ####\n",
    "\n",
    "```python\n",
    "\n",
    "print(\"Load ProtBERT Model...\")\n",
    "# PROT BERT LOADING :\n",
    "from transformers import BertModel, BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
    "model = BertModel.from_pretrained(\"Rostlab/prot_bert\").to(config.device)\n",
    "\n",
    "def get_bert_embedding(\n",
    "    sequence : str,\n",
    "    len_seq_limit : int\n",
    "):\n",
    "    '''\n",
    "    Function to collect last hidden state embedding vector from pre-trained ProtBERT Model\n",
    "    \n",
    "    INPUTS:\n",
    "    - sequence (str) : protein sequence (ex : AAABBB) from fasta file\n",
    "    - len_seq_limit (int) : maximum sequence lenght (i.e nb of letters) for truncation\n",
    "    \n",
    "    OUTPUTS:\n",
    "    - output_hidden : last hidden state embedding vector for input sequence of length 1024\n",
    "    '''\n",
    "    sequence_w_spaces = ' '.join(list(sequence))\n",
    "    encoded_input = tokenizer(\n",
    "        sequence_w_spaces,\n",
    "        truncation=True,\n",
    "        max_length=len_seq_limit,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt').to(config.device)\n",
    "    output = model(**encoded_input)\n",
    "    output_hidden = output['last_hidden_state'][:,0][0].detach().cpu().numpy()\n",
    "    assert len(output_hidden)==1024\n",
    "    return output_hidden\n",
    "\n",
    "### COLLECTING FOR TRAIN SAMPLES :\n",
    "print(\"Loading train set ProtBERT Embeddings...\")\n",
    "fasta_train = SeqIO.parse(config.train_sequences_path, \"fasta\")\n",
    "print(\"Total Nb of Elements : \", len(list(fasta_train)))\n",
    "fasta_train = SeqIO.parse(config.train_sequences_path, \"fasta\")\n",
    "ids_list = []\n",
    "embed_vects_list = []\n",
    "t0 = time.time()\n",
    "checkpoint = 0\n",
    "for item in tqdm(fasta_train):\n",
    "    ids_list.append(item.id)\n",
    "    embed_vects_list.append(\n",
    "        get_bert_embedding(sequence = item.seq, len_seq_limit = 1200))\n",
    "    checkpoint+=1\n",
    "    if checkpoint>=100:\n",
    "        df_res = pd.DataFrame(data={\"id\" : ids_list, \"embed_vect\" : embed_vects_list})\n",
    "        np.save('/kaggle/working/train_ids.npy',np.array(ids_list))\n",
    "        np.save('/kaggle/working/train_embeddings.npy',np.array(embed_vects_list))\n",
    "        checkpoint=0\n",
    "        \n",
    "np.save('/kaggle/working/train_ids.npy',np.array(ids_list))\n",
    "np.save('/kaggle/working/train_embeddings.npy',np.array(embed_vects_list))\n",
    "print('Total Elapsed Time:',time.time()-t0)\n",
    "\n",
    "### COLLECTING FOR TEST SAMPLES :\n",
    "print(\"Loading test set ProtBERT Embeddings...\")\n",
    "fasta_test = SeqIO.parse(config.test_sequences_path, \"fasta\")\n",
    "print(\"Total Nb of Elements : \", len(list(fasta_test)))\n",
    "fasta_test = SeqIO.parse(config.test_sequences_path, \"fasta\")\n",
    "ids_list = []\n",
    "embed_vects_list = []\n",
    "t0 = time.time()\n",
    "checkpoint=0\n",
    "for item in tqdm(fasta_test):\n",
    "    ids_list.append(item.id)\n",
    "    embed_vects_list.append(\n",
    "        get_bert_embedding(sequence = item.seq, len_seq_limit = 1200))\n",
    "    checkpoint+=1\n",
    "    if checkpoint>=100:\n",
    "        np.save('/kaggle/working/test_ids.npy',np.array(ids_list))\n",
    "        np.save('/kaggle/working/test_embeddings.npy',np.array(embed_vects_list))\n",
    "        checkpoint=0\n",
    "        \n",
    "np.save('/kaggle/working/test_ids.npy',np.array(ids_list))\n",
    "np.save('/kaggle/working/test_embeddings.npy',np.array(embed_vects_list))\n",
    "print('Total Elasped Time:',time.time()-t0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d6573",
   "metadata": {
    "papermill": {
     "duration": 0.014284,
     "end_time": "2023-05-23T08:57:31.080759",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.066475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Collect labels vectors for train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8bc1ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.111471Z",
     "iopub.status.busy": "2023-05-23T08:57:31.111108Z",
     "iopub.status.idle": "2023-05-23T08:57:31.124816Z",
     "shell.execute_reply": "2023-05-23T08:57:31.123908Z"
    },
    "papermill": {
     "duration": 0.031749,
     "end_time": "2023-05-23T08:57:31.126868",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.095119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProteinSequenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, datatype, embeddings_source, aspect=None):\n",
    "        super(ProteinSequenceDataset).__init__()\n",
    "        self.datatype = datatype\n",
    "        \n",
    "        if embeddings_source in [\"ProtBERT\", \"EMS2\", \"Ensemble2\"]:\n",
    "            embeds = np.load(\"/kaggle/input/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_embeddings.npy\")\n",
    "            ids = np.load(\"/kaggle/input/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_ids.npy\")\n",
    "        \n",
    "        if embeddings_source in [\"T5\", \"Ensemble1\"]:\n",
    "            embeds = np.load(\"/kaggle/input/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_embeds.npy\")\n",
    "            ids = np.load(\"/kaggle/input/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_ids.npy\")\n",
    "            \n",
    "        embeds_list = []\n",
    "        for l in range(embeds.shape[0]):\n",
    "            embeds_list.append(embeds[l,:])\n",
    "        self.df = pd.DataFrame(data={\"EntryID\": ids, \"embed\" : embeds_list})\n",
    "        \n",
    "        if datatype==\"train\":\n",
    "            if not aspect:\n",
    "                df_labels = pd.read_pickle(\n",
    "                    \"/kaggle/input/train-tragets-top-500\" + \\\n",
    "                    \"/train_targets_top\"+str(config.num_labels)+\".pkl\")\n",
    "            else:\n",
    "                df_labels = pd.read_pickle(\n",
    "                    f\"/kaggle/input/train-tragets-top-500/train_targets_{aspect}_top_{config.num_labels}.pkl\")\n",
    "            self.df = self.df.merge(df_labels, on=\"EntryID\",how=\"right\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        embed = torch.tensor(self.df.iloc[index][\"embed\"] , dtype = torch.float32)\n",
    "        if self.datatype==\"train\":\n",
    "            targets = torch.tensor(self.df.iloc[index][\"labels_vect\"], dtype = torch.float32)\n",
    "            return embed, targets\n",
    "        if self.datatype==\"test\":\n",
    "            id = self.df.iloc[index][\"EntryID\"]\n",
    "            return embed, id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f66ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T17:45:22.691183Z",
     "iopub.status.busy": "2023-05-11T17:45:22.690593Z",
     "iopub.status.idle": "2023-05-11T17:45:24.979748Z",
     "shell.execute_reply": "2023-05-11T17:45:24.978075Z",
     "shell.execute_reply.started": "2023-05-11T17:45:22.691147Z"
    },
    "papermill": {
     "duration": 0.014279,
     "end_time": "2023-05-23T08:57:31.155760",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.141481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### SCRIPT FOR LABELS (TARGETS) VECTORS COLLECTING #####\n",
    "#### RUN THIS ONLY ONE TIME AND SAVE IT IN LOCAL ####\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "print(\"GENERATE TARGETS FOR ENTRY IDS (\"+str(config.num_labels)+\" MOST COMMON GO TERMS)\")\n",
    "ids = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/train_ids.npy\")\n",
    "labels = pd.read_csv(config.train_labels_path, sep = \"\\t\")\n",
    "\n",
    "top_terms = labels.groupby(\"term\")[\"EntryID\"].count().sort_values(ascending=False)\n",
    "labels_names = top_terms[:config.num_labels].index.values\n",
    "train_labels_sub = labels[(labels.term.isin(labels_names)) & (labels.EntryID.isin(ids))]\n",
    "id_labels = train_labels_sub.groupby('EntryID')['term'].apply(list).to_dict()\n",
    "\n",
    "go_terms_map = {label: i for i, label in enumerate(labels_names)}\n",
    "labels_matrix = np.empty((len(ids), len(labels_names)))\n",
    "\n",
    "for index, id in tqdm(enumerate(ids),total = len(ids), position=0, leave=True):\n",
    "    id_gos_list = id_labels[id]\n",
    "    temp = [go_terms_map[go] for go in labels_names if go in id_gos_list]\n",
    "    labels_matrix[index, temp] = 1\n",
    "\n",
    "\n",
    "# 将labels_matrix转换为一个向量列表\n",
    "vectors = [row.ravel() for row in labels_matrix]\n",
    "\n",
    "# 创建一个新的DataFrame，其中包含向量和EntryID\n",
    "df = pd.DataFrame({'EntryID': ids, 'labels_vect': vectors})\n",
    "\n",
    "# 将DataFrame保存为pkl文件\n",
    "df.to_pickle(\"train_targets_top500.pkl\")\n",
    "\n",
    "assert 1==0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3effc8",
   "metadata": {
    "papermill": {
     "duration": 0.014331,
     "end_time": "2023-05-23T08:57:31.184534",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.170203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Pytorch Dataset Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b63cceff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.216624Z",
     "iopub.status.busy": "2023-05-23T08:57:31.214718Z",
     "iopub.status.idle": "2023-05-23T08:57:31.221068Z",
     "shell.execute_reply": "2023-05-23T08:57:31.220186Z"
    },
    "papermill": {
     "duration": 0.024062,
     "end_time": "2023-05-23T08:57:31.223179",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.199117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directories for the different embedding vectors : \n",
    "embeds_map = {\n",
    "    \"T5\" : \"t5embeds\",\n",
    "    \"ProtBERT\" : \"protbert-embeddings-for-cafa5\",\n",
    "    \"EMS2\" : \"cafa-5-ems-2-embeddings-numpy\",\n",
    "    \"Ensemble1\": \"ensemble-embedding-for-cfa\",\n",
    "    \"Ensemble2\": \"ensemble-embedding-for-cfa\",\n",
    "\n",
    "}\n",
    "\n",
    "# Length of the different embedding vectors :\n",
    "embeds_dim = {\n",
    "    \"T5\" : 1024,\n",
    "    \"ProtBERT\" : 1024,\n",
    "    \"EMS2\" : 1280,\n",
    "    \"Ensemble1\": 3328,\n",
    "    \"Ensemble2\": 2304,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809bb144",
   "metadata": {
    "papermill": {
     "duration": 0.014322,
     "end_time": "2023-05-23T08:57:31.252080",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.237758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Pytorch Models Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "900e127a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.284010Z",
     "iopub.status.busy": "2023-05-23T08:57:31.282475Z",
     "iopub.status.idle": "2023-05-23T08:57:31.290076Z",
     "shell.execute_reply": "2023-05-23T08:57:31.289186Z"
    },
    "papermill": {
     "duration": 0.02551,
     "end_time": "2023-05-23T08:57:31.292040",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.266530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, 1012),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.15),\n",
    "            torch.nn.Linear(1012, 712),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(712, 700),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.15),\n",
    "            torch.nn.Linear(700, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8d880c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.323273Z",
     "iopub.status.busy": "2023-05-23T08:57:31.321889Z",
     "iopub.status.idle": "2023-05-23T08:57:31.327004Z",
     "shell.execute_reply": "2023-05-23T08:57:31.326175Z"
    },
    "papermill": {
     "duration": 0.022407,
     "end_time": "2023-05-23T08:57:31.328922",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.306515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MultiLayerPerceptron(torch.nn.Module):\n",
    "#     def __init__(self, input_dim, num_classes):\n",
    "#         super(MultiLayerPerceptron, self).__init__()\n",
    "#         self.model = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(input_dim, 1024),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Dropout(0.2),\n",
    "#             torch.nn.Linear(1024, 2048),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Dropout(0.2),\n",
    "# #             torch.nn.Linear(2048, 2048),\n",
    "# #             torch.nn.ReLU(),\n",
    "# #             torch.nn.Dropout(0.2),\n",
    "#             torch.nn.Linear(2048, 1024),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Dropout(0.2),\n",
    "# #             torch.nn.Linear(1024, 1024),\n",
    "# #             torch.nn.ReLU(),\n",
    "# #             torch.nn.Dropout(0.2),\n",
    "#             torch.nn.Linear(1024, 512),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Dropout(0.2),\n",
    "#             torch.nn.Linear(512, num_classes),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.model(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acacac5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.359567Z",
     "iopub.status.busy": "2023-05-23T08:57:31.358968Z",
     "iopub.status.idle": "2023-05-23T08:57:31.363921Z",
     "shell.execute_reply": "2023-05-23T08:57:31.363089Z"
    },
    "papermill": {
     "duration": 0.022501,
     "end_time": "2023-05-23T08:57:31.365857",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.343356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MultiLayerPerceptron(torch.nn.Module):\n",
    "#     def __init__(self, input_dim, num_classes):\n",
    "#         super(MultiLayerPerceptron, self).__init__()\n",
    "#         self.model = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(input_dim, 1024),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Dropout(0.2),\n",
    "#             torch.nn.Linear(1024, 2048),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Dropout(0.2),\n",
    "#             torch.nn.Linear(2048, 2048),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Dropout(0.2),\n",
    "#             torch.nn.Linear(2048, 1024),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Dropout(0.2),\n",
    "#             torch.nn.Linear(1024, 1024),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Dropout(0.2),\n",
    "#             torch.nn.Linear(1024, num_classes),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.model(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fc71131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.396745Z",
     "iopub.status.busy": "2023-05-23T08:57:31.396171Z",
     "iopub.status.idle": "2023-05-23T08:57:31.404681Z",
     "shell.execute_reply": "2023-05-23T08:57:31.403788Z"
    },
    "papermill": {
     "duration": 0.026132,
     "end_time": "2023-05-23T08:57:31.406688",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.380556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=3, kernel_size=3, dilation=1, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=3, out_channels=8, kernel_size=3, dilation=1, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=int(8*input_dim/4), out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], 1, x.shape[1])\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb8a38f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.437453Z",
     "iopub.status.busy": "2023-05-23T08:57:31.437115Z",
     "iopub.status.idle": "2023-05-23T08:57:31.444649Z",
     "shell.execute_reply": "2023-05-23T08:57:31.443690Z"
    },
    "papermill": {
     "duration": 0.025313,
     "end_time": "2023-05-23T08:57:31.446665",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.421352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, hidden_dim=128, num_layers=2):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.lstm = nn.LSTM(input_size=self.input_dim, hidden_size=hidden_dim, num_layers=num_layers, bidirectional=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_dim*4, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1, self.input_dim).transpose(0, 1)\n",
    "        output, (hn, cn) = self.lstm(x)\n",
    "        hn = hn.view(hn.shape[1], -1)\n",
    "        x = self.fc(hn)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f66b05",
   "metadata": {
    "papermill": {
     "duration": 0.014267,
     "end_time": "2023-05-23T08:57:31.475504",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.461237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9760d2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.506808Z",
     "iopub.status.busy": "2023-05-23T08:57:31.506202Z",
     "iopub.status.idle": "2023-05-23T08:57:31.526026Z",
     "shell.execute_reply": "2023-05-23T08:57:31.525173Z"
    },
    "papermill": {
     "duration": 0.037931,
     "end_time": "2023-05-23T08:57:31.527999",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.490068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(embeddings_source, model_type=\"linear\", train_size=0.9, model_aspect=None):\n",
    "    if not model_aspect:\n",
    "        train_dataset = ProteinSequenceDataset(datatype=\"train\", embeddings_source = embeddings_source)\n",
    "        model_aspect = ''\n",
    "    else:\n",
    "        train_dataset = ProteinSequenceDataset(datatype=\"train\", embeddings_source = embeddings_source, aspect = model_aspect)\n",
    "    \n",
    "    train_set, val_set = random_split(train_dataset, lengths = [int(len(train_dataset)*train_size), len(train_dataset)-int(len(train_dataset)*train_size)])\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=config.batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_set, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    if model_type == \"linear\":\n",
    "        model = MultiLayerPerceptron(input_dim=embeds_dim[embeddings_source], num_classes=config.num_labels).to(config.device)\n",
    "    if model_type == \"convolutional\":\n",
    "        model = CNN1D(input_dim=embeds_dim[embeddings_source], num_classes=config.num_labels).to(config.device)\n",
    "    if model_type == \"BiLSTM\":\n",
    "        model = BiLSTM(input_dim=embeds_dim[embeddings_source], num_classes=config.num_labels).to(config.device)\n",
    "\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr = config.lr)\n",
    "    optimizer = AdamW(model.parameters(), lr=config.lr,weight_decay=1e-6)\n",
    "#     scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=1)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=800)\n",
    "\n",
    "    CrossEntropy = torch.nn.CrossEntropyLoss()\n",
    "    f1_score = MultilabelF1Score(num_labels=config.num_labels).to(config.device)\n",
    "    n_epochs = config.n_epochs\n",
    "\n",
    "    print(\"BEGIN TRAINING...\")\n",
    "    train_loss_history=[]\n",
    "    val_loss_history=[]\n",
    "    \n",
    "    train_f1score_history=[]\n",
    "    val_f1score_history=[]\n",
    "    best_score = 0\n",
    "    best_loss = 1000\n",
    "    stop_step = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"EPOCH \", epoch+1)\n",
    "        ## TRAIN PHASE :\n",
    "        losses = []\n",
    "        scores = []\n",
    "        for embed, targets in tqdm(train_dataloader):\n",
    "            embed, targets = embed.to(config.device), targets.to(config.device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(embed)\n",
    "            loss= CrossEntropy(preds, targets)\n",
    "            score=f1_score(preds, targets)\n",
    "            losses.append(loss.item()) \n",
    "            scores.append(score.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        avg_loss = np.mean(losses)\n",
    "        avg_score = np.mean(scores)\n",
    "\n",
    "        print(\"Running Average TRAIN Loss : \", avg_loss)\n",
    "        print(\"Running Average TRAIN F1-Score : \", avg_score)\n",
    "        train_loss_history.append(avg_loss)\n",
    "        train_f1score_history.append(avg_score)\n",
    "\n",
    "        ## VALIDATION PHASE : \n",
    "        losses = []\n",
    "        scores = []\n",
    "        for embed, targets in val_dataloader:\n",
    "            embed, targets = embed.to(config.device), targets.to(config.device)\n",
    "            preds = model(embed)\n",
    "            loss= CrossEntropy(preds, targets)\n",
    "            score=f1_score(preds, targets)\n",
    "            losses.append(loss.item())\n",
    "            scores.append(score.item())\n",
    "        avg_loss = np.mean(losses)\n",
    "        avg_score = np.mean(scores)\n",
    "        print(\"Running Average VAL Loss : \", avg_loss)\n",
    "        print(\"Running Average VAL F1-Score : \", avg_score)\n",
    "        val_loss_history.append(avg_loss)\n",
    "        val_f1score_history.append(avg_score)\n",
    "        \n",
    "        scheduler.step(avg_loss)\n",
    "        print(\"\\n\")\n",
    "        if avg_score > best_score and avg_loss < best_loss:\n",
    "            best_score = avg_score\n",
    "            best_loss = avg_loss\n",
    "            stop_step = 0\n",
    "            torch.save(model.state_dict(), f'{model_aspect}_{embeddings_source}_{config.num_labels}_{model_type}_{best_score}.pth')\n",
    "        else:\n",
    "            stop_step += 1\n",
    "            if stop_step==config.early_stop:\n",
    "                break\n",
    "    print(\"TRAINING FINISHED\")\n",
    "    print(\"FINAL TRAINING SCORE : \", train_f1score_history[-1])\n",
    "    print(\"FINAL VALIDATION SCORE : \", val_f1score_history[-1])\n",
    "    \n",
    "    losses_history = {\"train\" : train_loss_history, \"val\" : val_loss_history}\n",
    "    scores_history = {\"train\" : train_f1score_history, \"val\" : val_f1score_history}\n",
    "    del train_dataset, train_set, val_set\n",
    "    gc.collect()\n",
    "    return model, losses_history, scores_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc63cfc",
   "metadata": {
    "papermill": {
     "duration": 0.014229,
     "end_time": "2023-05-23T08:57:31.556930",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.542701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7.1. Training Usecase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f8a63",
   "metadata": {
    "papermill": {
     "duration": 0.014307,
     "end_time": "2023-05-23T08:57:31.585636",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.571329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### BPO_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83ea952f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.616060Z",
     "iopub.status.busy": "2023-05-23T08:57:31.615251Z",
     "iopub.status.idle": "2023-05-23T08:57:31.619631Z",
     "shell.execute_reply": "2023-05-23T08:57:31.618836Z"
    },
    "papermill": {
     "duration": 0.02146,
     "end_time": "2023-05-23T08:57:31.621502",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.600042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensem_model_BPO, ensem_losses_BPO, ensem_scores_BPO = train_model(embeddings_source=\"Ensemble2\",model_type=\"linear\",model_aspect=\"BPO\")\n",
    "# ems2_model_BPO, ems2_losses_BPO, ems2_scores_BPO = train_model(embeddings_source=\"EMS2\",model_type=\"linear\",model_aspect=\"BPO\")\n",
    "# t5_model_BPO, t5_losses_BPO, t5_scores_BPO = train_model(embeddings_source=\"T5\",model_type=\"linear\",model_aspect=\"BPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d8edc30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.652756Z",
     "iopub.status.busy": "2023-05-23T08:57:31.651828Z",
     "iopub.status.idle": "2023-05-23T08:57:31.657244Z",
     "shell.execute_reply": "2023-05-23T08:57:31.656360Z"
    },
    "papermill": {
     "duration": 0.02317,
     "end_time": "2023-05-23T08:57:31.659315",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.636145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (10, 4))\n",
    "# # plt.plot(ems2_losses_BPO[\"val\"], label = \"ems2_losses_BPO\")\n",
    "# # plt.plot(t5_losses_BPO[\"val\"], label = \"t5_losses_BPO\")\n",
    "# plt.plot(ensem_losses_BPO[\"val\"], label = \"ensem_losses_BPO\")\n",
    "# # plt.plot(ProtBERT_losses_BPO[\"val\"], label = \"ProtBERT\")\n",
    "# plt.title(\"Validation Losses for # Vector Embeddings\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Average Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize = (10, 4))\n",
    "# # plt.plot(ems2_scores_BPO[\"val\"], label = \"ems2_scores_BPO\")\n",
    "# # plt.plot(t5_scores_BPO[\"val\"], label = \"t5_scores_BPO\")\n",
    "# plt.plot(ensem_scores_BPO[\"val\"], label = \"ensem_scores_BPO\")\n",
    "# # plt.plot(ProtBERT_scores_BPO[\"val\"], label = \"ProtBERT\")\n",
    "# plt.title(\"Validation F1-Scores for # Vector Embeddings\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Average F1-Score\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220bfb03",
   "metadata": {
    "papermill": {
     "duration": 0.014468,
     "end_time": "2023-05-23T08:57:31.688402",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.673934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### CCO_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dc3a27f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.718985Z",
     "iopub.status.busy": "2023-05-23T08:57:31.718357Z",
     "iopub.status.idle": "2023-05-23T08:57:31.722544Z",
     "shell.execute_reply": "2023-05-23T08:57:31.721651Z"
    },
    "papermill": {
     "duration": 0.021762,
     "end_time": "2023-05-23T08:57:31.724602",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.702840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensem_model_CCO, ensem_losses_CCO, ensem_scores_CCO = train_model(embeddings_source=\"Ensemble2\",model_type=\"linear\",model_aspect=\"CCO\")\n",
    "# ems2_model_CCO, ems2_losses_CCO, ems2_scores_CCO = train_model(embeddings_source=\"EMS2\",model_type=\"linear\",model_aspect=\"CCO\")\n",
    "# t5_model_CCO, t5_losses_CCO, t5_scores_CCO = train_model(embeddings_source=\"T5\",model_type=\"linear\",model_aspect=\"CCO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf699f63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.755060Z",
     "iopub.status.busy": "2023-05-23T08:57:31.754307Z",
     "iopub.status.idle": "2023-05-23T08:57:31.759183Z",
     "shell.execute_reply": "2023-05-23T08:57:31.758391Z"
    },
    "papermill": {
     "duration": 0.02203,
     "end_time": "2023-05-23T08:57:31.761043",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.739013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (10, 4))\n",
    "# # plt.plot(ems2_losses_CCO[\"val\"], label = \"ems2_losses_CCO\")\n",
    "# # plt.plot(t5_losses_CCO[\"val\"], label = \"t5_losses_CCO\")\n",
    "# plt.plot(ensem_losses_CCO[\"val\"], label = \"ensem_losses_CCO\")\n",
    "# # plt.plot(protbert_losses[\"val\"], label = \"ProtBERT\")\n",
    "# plt.title(\"Validation Losses for # Vector Embeddings\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Average Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize = (10, 4))\n",
    "# # plt.plot(ems2_scores_CCO[\"val\"], label = \"ems2_scores_CCO\")\n",
    "# # plt.plot(t5_scores_CCO[\"val\"], label = \"t5_scores_CCO\")\n",
    "# plt.plot(ensem_scores_CCO[\"val\"], label = \"ensem_scores_CCO\")\n",
    "# # plt.plot(protbert_scores[\"val\"], label = \"ProtBERT\")\n",
    "# plt.title(\"Validation F1-Scores for # Vector Embeddings\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Average F1-Score\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717529ab",
   "metadata": {
    "papermill": {
     "duration": 0.014174,
     "end_time": "2023-05-23T08:57:31.789601",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.775427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### MFO_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a462befd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.819496Z",
     "iopub.status.busy": "2023-05-23T08:57:31.819025Z",
     "iopub.status.idle": "2023-05-23T08:57:31.822725Z",
     "shell.execute_reply": "2023-05-23T08:57:31.821902Z"
    },
    "papermill": {
     "duration": 0.020708,
     "end_time": "2023-05-23T08:57:31.824618",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.803910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensem_model_MFO, ensem_losses_MFO, ensem_scores_MFO = train_model(embeddings_source=\"Ensemble2\",model_type=\"linear\",model_aspect=\"MFO\")\n",
    "# ems2_model_MFO, ems2_losses_MFO, ems2_scores_MFO = train_model(embeddings_source=\"EMS2\",model_type=\"linear\",model_aspect=\"MFO\")\n",
    "# t5_model_MFO, t5_losses_MFO, t5_scores_MFO = train_model(embeddings_source=\"T5\",model_type=\"linear\",model_aspect=\"MFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e00d265b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.854448Z",
     "iopub.status.busy": "2023-05-23T08:57:31.854043Z",
     "iopub.status.idle": "2023-05-23T08:57:31.858483Z",
     "shell.execute_reply": "2023-05-23T08:57:31.857543Z"
    },
    "papermill": {
     "duration": 0.02144,
     "end_time": "2023-05-23T08:57:31.860389",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.838949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (10, 4))\n",
    "# # plt.plot(ems2_losses_MFO[\"val\"], label = \"ems2_losses_MFO\")\n",
    "# # plt.plot(t5_losses_MFO[\"val\"], label = \"t5_losses_MFO\")\n",
    "# plt.plot(ensem_losses_MFO[\"val\"], label = \"ensem_losses_MFO\")\n",
    "# # plt.plot(protbert_losses[\"val\"], label = \"ProtBERT\")\n",
    "# plt.title(\"Validation Losses for # Vector Embeddings\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Average Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize = (10, 4))\n",
    "# # plt.plot(ems2_scores_MFO[\"val\"], label = \"ems2_scores_MFO\")\n",
    "# # plt.plot(t5_scores_MFO[\"val\"], label = \"t5_scores_MFO\")\n",
    "# plt.plot(ensem_scores_MFO[\"val\"], label = \"ensem_scores_MFO\")\n",
    "# # plt.plot(protbert_scores[\"val\"], label = \"ProtBERT\")\n",
    "# plt.title(\"Validation F1-Scores for # Vector Embeddings\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Average F1-Score\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80680a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.892158Z",
     "iopub.status.busy": "2023-05-23T08:57:31.890586Z",
     "iopub.status.idle": "2023-05-23T08:57:31.895261Z",
     "shell.execute_reply": "2023-05-23T08:57:31.894430Z"
    },
    "papermill": {
     "duration": 0.022161,
     "end_time": "2023-05-23T08:57:31.897217",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.875056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# protbert_model, protbert_losses, protbert_scores = train_model(embeddings_source=\"ProtBERT\",model_type=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18437294",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.928879Z",
     "iopub.status.busy": "2023-05-23T08:57:31.927308Z",
     "iopub.status.idle": "2023-05-23T08:57:31.932029Z",
     "shell.execute_reply": "2023-05-23T08:57:31.931184Z"
    },
    "papermill": {
     "duration": 0.022296,
     "end_time": "2023-05-23T08:57:31.933988",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.911692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# t5_convmodel, t5_convlosses, t5_convscores = train_model(embeddings_source=\"T5\",model_type=\"convolutional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd5f5fce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:31.966371Z",
     "iopub.status.busy": "2023-05-23T08:57:31.964842Z",
     "iopub.status.idle": "2023-05-23T08:57:31.969624Z",
     "shell.execute_reply": "2023-05-23T08:57:31.968755Z"
    },
    "papermill": {
     "duration": 0.023056,
     "end_time": "2023-05-23T08:57:31.971691",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.948635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# t5_LSTMmodel, t5_LSTMlosses, t5_LSTMscores = train_model(embeddings_source=\"T5\",model_type=\"BiLSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606fda26",
   "metadata": {
    "papermill": {
     "duration": 0.01435,
     "end_time": "2023-05-23T08:57:32.001542",
     "exception": false,
     "start_time": "2023-05-23T08:57:31.987192",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7.3. Train/Val Losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27b6c58c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:32.033068Z",
     "iopub.status.busy": "2023-05-23T08:57:32.031715Z",
     "iopub.status.idle": "2023-05-23T08:57:32.036748Z",
     "shell.execute_reply": "2023-05-23T08:57:32.035919Z"
    },
    "papermill": {
     "duration": 0.02227,
     "end_time": "2023-05-23T08:57:32.038656",
     "exception": false,
     "start_time": "2023-05-23T08:57:32.016386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (10, 4))\n",
    "# # plt.plot(ems2_losses[\"val\"], label = \"EMS2\")\n",
    "# # plt.plot(t5_losses[\"val\"], label = \"T5\")\n",
    "# plt.plot(ensem_losses[\"val\"], label = \"ensem\")\n",
    "# # plt.plot(protbert_losses[\"val\"], label = \"ProtBERT\")\n",
    "# plt.title(\"Validation Losses for # Vector Embeddings\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Average Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize = (10, 4))\n",
    "# # plt.plot(ems2_scores[\"val\"], label = \"EMS2\")\n",
    "# # plt.plot(t5_scores[\"val\"], label = \"T5\")\n",
    "# plt.plot(ensem_scores[\"val\"], label = \"ensem\")\n",
    "# # plt.plot(protbert_scores[\"val\"], label = \"ProtBERT\")\n",
    "# plt.title(\"Validation F1-Scores for # Vector Embeddings\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Average F1-Score\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1928024",
   "metadata": {
    "papermill": {
     "duration": 0.0143,
     "end_time": "2023-05-23T08:57:32.067304",
     "exception": false,
     "start_time": "2023-05-23T08:57:32.053004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8. Pytorch Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3352e025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:32.097808Z",
     "iopub.status.busy": "2023-05-23T08:57:32.097290Z",
     "iopub.status.idle": "2023-05-23T08:57:32.113310Z",
     "shell.execute_reply": "2023-05-23T08:57:32.112476Z"
    },
    "papermill": {
     "duration": 0.033483,
     "end_time": "2023-05-23T08:57:32.115182",
     "exception": false,
     "start_time": "2023-05-23T08:57:32.081699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Linear_Lightning(pl.LightningModule):\n",
    "    def __init__(self, input_dim, num_classes, train_size, **hparams):\n",
    "        super(Linear_Lightning, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(input_dim, 1012)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(1012, 712)\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(712, num_classes)\n",
    "        \n",
    "        train_dataset = ProteinSequenceDataset(datatype=\"train\", embeddings_source = embeddings_source)\n",
    "        self.train_set, self.val_set = random_split(train_dataset, lengths = [int(len(train_dataset)*train_size), len(train_dataset)-int(len(train_dataset)*train_size)])\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.f1_score = MultilabelF1Score(num_labels=num_classes)\n",
    "        self.accuracy = MultilabelAccuracy(num_labels=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        embed, targets = batch\n",
    "        preds = self(embed)\n",
    "        loss = self.loss_fn(preds, targets)\n",
    "        f1_score = self.f1_score(preds, targets)\n",
    "        acc_score = self.accuracy(preds, targets)\n",
    "        \n",
    "        logs = {\"train_loss\" : loss, \"f1_score\" : f1_score, \"accuracy_score\" : acc_score}\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\":loss, \"log\" : logs}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        embed, targets = batch\n",
    "        preds = self(embed)\n",
    "        loss= self.loss_fn(preds, targets)\n",
    "        f1_score = self.f1_score(preds, targets)\n",
    "        acc_score = self.accuracy(preds, targets)\n",
    "        \n",
    "        return {\"val_loss\":loss, \"f1_score\" : f1_score, \"accuracy_score\" : acc_score}\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in ouputs]).mean()\n",
    "        logs = {\"val_loss\" : avg_loss}\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"avg_val_loss\" : avg_loss, \"log\" : logs}\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        val_dataloader = torch.utils.data.DataLoader(self.val_set, batch_size=config.batch_size, shuffle=False,)\n",
    "        return val_dataloader\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_dataloader = torch.utils.data.DataLoader(self.train_set, batch_size=self.batch_size, shuffle=False)\n",
    "        return train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f60acd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T21:06:26.807432Z",
     "iopub.status.busy": "2023-05-11T21:06:26.806291Z",
     "iopub.status.idle": "2023-05-11T21:06:30.034869Z",
     "shell.execute_reply": "2023-05-11T21:06:30.033213Z",
     "shell.execute_reply.started": "2023-05-11T21:06:26.807367Z"
    },
    "papermill": {
     "duration": 0.014619,
     "end_time": "2023-05-23T08:57:32.144583",
     "exception": false,
     "start_time": "2023-05-23T08:57:32.129964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## IN PROGRESS\n",
    "```python\n",
    "param_grid = {\n",
    "    \"batch_size\" : [8, 16, 32, 64],\n",
    "    \"lr\" : [1e-4, 1e-3, 1e-2]\n",
    "}\n",
    "\n",
    "embeddings_source = \"T5\"\n",
    "\n",
    "runs_count=0\n",
    "for batch_size in param_grid[\"batch_size\"]:\n",
    "    for lr in param_grid[\"lr\"]:\n",
    "        runs_count+=1\n",
    "        print(\"NEW SESSION RUN (number \"+str(runs_count)+\")\")\n",
    "        print(\"batch size : \", batch_size)\n",
    "        print(\"learning rate : \", lr)\n",
    "        \n",
    "        run_name = \"Adam-\"+str(batch_size)+\"-\"+str(lr)\n",
    "        \n",
    "        logger = WandbLogger(\n",
    "            name = run_name,\n",
    "            project=\"mlp_model_cafa5\",\n",
    "            job_type=\"train\"\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            max_epochs=1,\n",
    "            limit_train_batches=5000,\n",
    "            logger=logger\n",
    "        )\n",
    "        model = Linear_Lightning(\n",
    "            input_dim=embeds_dim[embeddings_source],\n",
    "            num_classes=config.num_labels,\n",
    "            train_size=0.8\n",
    "        )\n",
    "\n",
    "        trainer.fit(model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92838825",
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.014312,
     "end_time": "2023-05-23T08:57:32.173417",
     "exception": false,
     "start_time": "2023-05-23T08:57:32.159105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "# Define sweep config\n",
    "sweep_configuration = {\n",
    "    'method': 'random',\n",
    "    'name': 'sweep',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc'},\n",
    "    'parameters': \n",
    "    {\n",
    "        'batch_size': {'values': [16, 32, 64]},\n",
    "        'epochs': {'values': [5, 10, 15]},\n",
    "        'lr': {'max': 0.1, 'min': 0.0001}\n",
    "     }\n",
    "}\n",
    "\n",
    "# Initialize sweep by passing in config. \n",
    "# (Optional) Provide a name of the project.\n",
    "sweep_id = wandb.sweep(\n",
    "  sweep=sweep_configuration, \n",
    "  project='my-first-sweep'\n",
    "  )\n",
    "\n",
    "# Define training function that takes in hyperparameter \n",
    "# values from `wandb.config` and uses them to train a \n",
    "# model and return metric\n",
    "def train_one_epoch(epoch, lr, bs): \n",
    "  acc = 0.25 + ((epoch/30) +  (random.random()/10))\n",
    "  loss = 0.2 + (1 - ((epoch-1)/10 +  random.random()/5))\n",
    "  return acc, loss\n",
    "\n",
    "def evaluate_one_epoch(epoch): \n",
    "  acc = 0.1 + ((epoch/20) +  (random.random()/10))\n",
    "  loss = 0.25 + (1 - ((epoch-1)/10 +  random.random()/6))\n",
    "  return acc, loss\n",
    "\n",
    "def main():\n",
    "    run = wandb.init()\n",
    "\n",
    "    lr  =  wandb.config.lr\n",
    "    bs = wandb.config.batch_size\n",
    "    epochs = wandb.config.epochs\n",
    "\n",
    "    for epoch in np.arange(1, epochs):\n",
    "      train_acc, train_loss = train_one_epoch(epoch, lr, bs)\n",
    "      val_acc, val_loss = evaluate_one_epoch(epoch)\n",
    "\n",
    "      wandb.log({\n",
    "        'epoch': epoch, \n",
    "        'train_acc': train_acc,\n",
    "        'train_loss': train_loss, \n",
    "        'val_acc': val_acc, \n",
    "        'val_loss': val_loss\n",
    "      })\n",
    "\n",
    "# Start sweep job.\n",
    "wandb.agent(sweep_id, function=main, count=4)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728142f",
   "metadata": {
    "papermill": {
     "duration": 0.014343,
     "end_time": "2023-05-23T08:57:32.202359",
     "exception": false,
     "start_time": "2023-05-23T08:57:32.188016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 9. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5332878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:32.233399Z",
     "iopub.status.busy": "2023-05-23T08:57:32.233030Z",
     "iopub.status.idle": "2023-05-23T08:57:32.244884Z",
     "shell.execute_reply": "2023-05-23T08:57:32.244000Z"
    },
    "papermill": {
     "duration": 0.029783,
     "end_time": "2023-05-23T08:57:32.246869",
     "exception": false,
     "start_time": "2023-05-23T08:57:32.217086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(embeddings_source, model, aspect=None):\n",
    "    test_dataset = ProteinSequenceDataset(datatype=\"test\", embeddings_source = embeddings_source)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    del test_dataset\n",
    "    \n",
    "#     if embeddings_source == \"T5\":\n",
    "#         model = t5_model\n",
    "#     if embeddings_source == \"ProtBERT\":\n",
    "#         model = protbert_model\n",
    "#     if embeddings_source == \"EMS2\":\n",
    "#         model = ems2_model\n",
    "#     if embeddings_source == 'Ensemble':\n",
    "#         model = ensem_model\n",
    "    model.eval()\n",
    "    labels = pd.read_csv(config.train_labels_path, sep = \"\\t\")\n",
    "    if not aspect:\n",
    "        print(f\"Generate for all aspect\")\n",
    "        top_terms = labels.groupby(\"term\")[\"EntryID\"].count().sort_values(ascending=False)\n",
    "    else:\n",
    "        print(f\"Generate for {aspect}\")\n",
    "        labels = labels[labels.aspect==f\"{aspect}\"]\n",
    "        top_terms = labels.groupby(\"term\")[\"EntryID\"].count().sort_values(ascending=False)\n",
    "    labels_names = top_terms[:config.num_labels].index.values\n",
    "    print(\"GENERATE PREDICTION FOR TEST SET...\")\n",
    "\n",
    "    ids_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=object)\n",
    "    go_terms_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=object)\n",
    "    confs_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=np.float32)\n",
    "\n",
    "    for i, (embed, id) in tqdm(enumerate(test_dataloader),total = len(test_dataloader), position=0, leave=True):\n",
    "        embed = embed.to(config.device)\n",
    "        confs_[i*config.num_labels:(i+1)*config.num_labels] = torch.nn.functional.sigmoid(model(embed)).squeeze().detach().cpu().numpy()\n",
    "        ids_[i*config.num_labels:(i+1)*config.num_labels] = id[0]\n",
    "        go_terms_[i*config.num_labels:(i+1)*config.num_labels] = labels_names\n",
    "\n",
    "    submission_df = pd.DataFrame(data={\"Id\" : ids_, \"GO term\" : go_terms_, \"Confidence\" : confs_})\n",
    "    print(\"PREDICTIONS DONE\")\n",
    "    gc.collect()\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a205ee1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:32.276990Z",
     "iopub.status.busy": "2023-05-23T08:57:32.276715Z",
     "iopub.status.idle": "2023-05-23T08:57:32.280564Z",
     "shell.execute_reply": "2023-05-23T08:57:32.279618Z"
    },
    "papermill": {
     "duration": 0.021125,
     "end_time": "2023-05-23T08:57:32.282436",
     "exception": false,
     "start_time": "2023-05-23T08:57:32.261311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del ensem_losses_MFO, ensem_scores_MFO,ensem_losses_BPO, ensem_scores_BPO, ensem_losses_CCO, ensem_scores_CCO\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dce94a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:32.312388Z",
     "iopub.status.busy": "2023-05-23T08:57:32.312081Z",
     "iopub.status.idle": "2023-05-23T08:57:37.446768Z",
     "shell.execute_reply": "2023-05-23T08:57:37.445860Z"
    },
    "papermill": {
     "duration": 5.152052,
     "end_time": "2023-05-23T08:57:37.448852",
     "exception": false,
     "start_time": "2023-05-23T08:57:32.296800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensem_model_BPO = MultiLayerPerceptron(input_dim=2304, num_classes=config.num_labels).to(config.device)\n",
    "st = torch.load('/kaggle/input/cfca-models/BPO_Ensemble2_500_linear_0.2250145967692545.pth')\n",
    "ensem_model_BPO.load_state_dict(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f75ab72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T08:57:37.480702Z",
     "iopub.status.busy": "2023-05-23T08:57:37.479897Z",
     "iopub.status.idle": "2023-05-23T09:04:01.262424Z",
     "shell.execute_reply": "2023-05-23T09:04:01.261325Z"
    },
    "papermill": {
     "duration": 383.80072,
     "end_time": "2023-05-23T09:04:01.264978",
     "exception": false,
     "start_time": "2023-05-23T08:57:37.464258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate for BPO\n",
      "GENERATE PREDICTION FOR TEST SET...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141865/141865 [01:44<00:00, 1360.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS DONE\n"
     ]
    }
   ],
   "source": [
    "submission_1 = predict(\"Ensemble2\",model=ensem_model_BPO,aspect=\"BPO\")\n",
    "del ensem_model_BPO,st\n",
    "gc.collect()\n",
    "submission_1.to_csv('submission1.tsv', sep='\\t', index=False)\n",
    "del submission_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cda7a012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:04:01.444879Z",
     "iopub.status.busy": "2023-05-23T09:04:01.443868Z",
     "iopub.status.idle": "2023-05-23T09:04:01.935814Z",
     "shell.execute_reply": "2023-05-23T09:04:01.934920Z"
    },
    "papermill": {
     "duration": 0.584301,
     "end_time": "2023-05-23T09:04:01.937882",
     "exception": false,
     "start_time": "2023-05-23T09:04:01.353581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensem_model_CCO = MultiLayerPerceptron(input_dim=2304, num_classes=config.num_labels).to(config.device)\n",
    "st = torch.load('/kaggle/input/cfca-models/CCO_Ensemble2_500_linear_0.14624455499730699.pth')\n",
    "ensem_model_CCO.load_state_dict(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b2b9996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:04:02.115077Z",
     "iopub.status.busy": "2023-05-23T09:04:02.114730Z",
     "iopub.status.idle": "2023-05-23T09:10:23.064244Z",
     "shell.execute_reply": "2023-05-23T09:10:23.063236Z"
    },
    "papermill": {
     "duration": 381.041649,
     "end_time": "2023-05-23T09:10:23.067224",
     "exception": false,
     "start_time": "2023-05-23T09:04:02.025575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate for CCO\n",
      "GENERATE PREDICTION FOR TEST SET...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141865/141865 [01:44<00:00, 1363.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS DONE\n"
     ]
    }
   ],
   "source": [
    "submission_2 = predict(\"Ensemble2\",model=ensem_model_CCO,aspect=\"CCO\")\n",
    "del ensem_model_CCO,st\n",
    "gc.collect()\n",
    "submission_2.to_csv('submission2.tsv', sep='\\t', index=False)\n",
    "del submission_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2ac8a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:10:23.399529Z",
     "iopub.status.busy": "2023-05-23T09:10:23.399156Z",
     "iopub.status.idle": "2023-05-23T09:10:23.893446Z",
     "shell.execute_reply": "2023-05-23T09:10:23.892554Z"
    },
    "papermill": {
     "duration": 0.665355,
     "end_time": "2023-05-23T09:10:23.895810",
     "exception": false,
     "start_time": "2023-05-23T09:10:23.230455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensem_model_MFO = MultiLayerPerceptron(input_dim=2304, num_classes=config.num_labels).to(config.device)\n",
    "st = torch.load('/kaggle/input/cfca-models/MFO_Ensemble2_500_linear_0.15245565555749402.pth')\n",
    "ensem_model_MFO.load_state_dict(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f674840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:10:24.220900Z",
     "iopub.status.busy": "2023-05-23T09:10:24.219916Z",
     "iopub.status.idle": "2023-05-23T09:16:48.778758Z",
     "shell.execute_reply": "2023-05-23T09:16:48.777702Z"
    },
    "papermill": {
     "duration": 384.723695,
     "end_time": "2023-05-23T09:16:48.781305",
     "exception": false,
     "start_time": "2023-05-23T09:10:24.057610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate for MFO\n",
      "GENERATE PREDICTION FOR TEST SET...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141865/141865 [01:44<00:00, 1356.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS DONE\n"
     ]
    }
   ],
   "source": [
    "submission_3 = predict(\"Ensemble2\",model=ensem_model_MFO,aspect=\"MFO\")\n",
    "del ensem_model_MFO,st\n",
    "gc.collect()\n",
    "submission_3.to_csv('submission3.tsv', sep='\\t', index=False)\n",
    "del submission_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "026b6ae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:16:49.259284Z",
     "iopub.status.busy": "2023-05-23T09:16:49.258110Z",
     "iopub.status.idle": "2023-05-23T09:16:49.263372Z",
     "shell.execute_reply": "2023-05-23T09:16:49.262386Z"
    },
    "papermill": {
     "duration": 0.247872,
     "end_time": "2023-05-23T09:16:49.265547",
     "exception": false,
     "start_time": "2023-05-23T09:16:49.017675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if t5_scores[\"val\"][-1] > ems2_scores[\"val\"][-1]:\n",
    "#     print('T5')\n",
    "#     submission_1 = predict(\"T5\")\n",
    "# else:\n",
    "#     print('EMS')\n",
    "#     submission_1 = predict(\"EMS2\")\n",
    "# submission_3 = predict(\"ProtBERT\")\n",
    "# submission_1['Confidence'] = 0.5*submission_1['Confidence']+0.4*submission_2['Confidence']+0.1*submission_3['Confidence']\n",
    "# del submission_2,submission_3\n",
    "# submission_1.shape,submission_2.shape,submission_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3847ca4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:16:49.794370Z",
     "iopub.status.busy": "2023-05-23T09:16:49.793724Z",
     "iopub.status.idle": "2023-05-23T09:16:49.798036Z",
     "shell.execute_reply": "2023-05-23T09:16:49.797088Z"
    },
    "papermill": {
     "duration": 0.294806,
     "end_time": "2023-05-23T09:16:49.799987",
     "exception": false,
     "start_time": "2023-05-23T09:16:49.505181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission_1 = pd.concat([submission_1, submission_2, submission_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a2709ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:16:50.274341Z",
     "iopub.status.busy": "2023-05-23T09:16:50.273987Z",
     "iopub.status.idle": "2023-05-23T09:16:50.278064Z",
     "shell.execute_reply": "2023-05-23T09:16:50.277182Z"
    },
    "papermill": {
     "duration": 0.244197,
     "end_time": "2023-05-23T09:16:50.280178",
     "exception": false,
     "start_time": "2023-05-23T09:16:50.035981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission_1.to_csv('submission1.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1187.339739,
   "end_time": "2023-05-23T09:16:54.083964",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-23T08:57:06.744225",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
